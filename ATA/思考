1. 125128
  1) 智能图文生成、布局
  2) 关于智能图文布局，排版结构有3种单栏、双栏、三栏，每一种上又可以加上推荐理由、优惠价格等多种装饰元素，
      这样叉乘下来有24种不同的布局，利用布局特征，用户特征，交叉特征学习不同用户群对布局的偏好。
  3) 在66892和125182这两篇文章中都提到如何进行流量分配的思路，66892这篇文章cij表示用户i对行业j的点击率，xij表示将行业j分配给用户i的概率，
     因此也是解带限制的优化问题，max Sum(xij*cij), st sum_j(xij) <= 1, sum_i(xij) = bi。 具体落地的框架是，基于上面的拉格朗日计算出一个调控因子，
     然后参照调控因子进行调控。
  4) 125182这篇文章中，有三种调权方式，[1] boost加权，对该类别下的所有商品都做了相同的累加 加权，缺点是会把一些差的商品也带上来；
     [2] weighted加权，乘上一个因子加权， 这个对商品有一定的区分度，原来ctr高的商品获得的影响也要大一些，这个效果比1好 [3] logitboost，
     根据ctr反推，logit乘以一个权重，再计算初ctr.
     
2. 125652
1) 第一代Query改写方法为SimRank++，其缺陷为主要考虑query和bidword之间的语义相关性，而未考虑bidword侧的流量机制，难以释放营收潜力。
2) 第二代参照雅虎的论文，Optimizing Query Rewrites For Keyword-based Advertising, 直接计算Query对应的优质广告集合，再反过来选取bidword，
实现了对广告的最大覆盖。该算法存在的缺陷，将整个Query视作一个整体，同时其原理是基于统计的记忆模型
3）第三代是DeepNB，对query进行分词处理，获取词对应的Embedding，将该Embedding一方面取平均，另一方面交给cnn捕获n-gram信息，cnn后接Attention网络，
   对于。 同时将头部query的ID直接Embedding，这是为了记住头部query的特性。将用户的信息也放进去，实现个性化的query改写。
   基于上面三个向量加权和再接三层FC。 bidword就直接根据ID embedding，然后计算DSSM。
4) 训练样本如何得到，如果将query点击过的广告的bidword都保留，样本就太多了，因此price(ad, bidword) / log(bidword的广告数 + 1)，
    用该分数对该广告下所有bid算分，进而计算百分比。 

3. 125424
1) 关于Attention GRU的改进思路可以借鉴：[1] 不同的行为有不同的权重，加购的权重比点击的权重要更大，因此对原lstm的d维的hidden state
   重新做了一个投影(用一个d*d维的矩阵) [2] 引入时间衰减因子，不同时间的行为对当前的影响也不同。[3] 排序的时候要考虑trigger item的信息。
   
4. 121438
1) 基于异构网络元路径embedding表征的大规模关键词推荐
2) 所做的事情就是在手淘的搜索框中，推荐默认的搜索词，做法是采用基于异构网络元路劲法
3) 具体做法：构建user-item-query的异构网络， 为每种类型的节点构造多条元路径，比如对user可以构造metapath1: user->item->query(用户点击过的商品，
    商品主要被哪些query引导)，也可以构建metapath2: user->query->item(用户的搜索query，query下点击的最多的item)。 
    对query和item的最开始的表示是基于分词后的term的embedding直接平均，然后对metapath1中的item，根据query来获得，user根据item来获得。
    对metapath2中的query根据item来获得，user跟军query来获得。 所以最原始的参数就是term对应的embbeding参数，这样做可以减少参数量。
    
5. 102403
1) 基于树的向量召回不能用概率连乘树，原因是word2vec中的概率连乘树适用于路径已经给定的情况下来计算概率，而用作召回时需要计算所有叶子节点的概率。
2) 另一个原因是，层次softmax倾向于将某种程度上相似的节点组织成兄弟节点，进行优和次优的判断。但推荐和召回往往是对相似的一类要么整体感兴趣，
   要么整体不感兴趣，因此建树的时候，兄弟节点间应该是不同的类。
3) 训练的时候，将用户当天行为的叶子节点(购买,点击)以及其所有祖先节点作为正例，其它同层的兄弟节点左右负样本。
4) 里面提到关于树构建的思路比较有借鉴意义，先基于原始的商品树进行训练，得到每个节点的向量，然后再对向量使用kmeans重新聚类。 

6. 127256
1) 迁移学习的有效性很大程度上取决于source domain和target domain之间的差异，如果差异很大，则迁移很可能是无效的。
2) 避免domain gap的方法通常使用样本迁移，找出合适的源样本去帮助target domain。该论文使用强化学习来提升样本迁移能力，找出合适的样本来帮助target domain
3) 论文Learning to selectively Transfer: Reinforced Transfer Learning for Deep Text Matching
4) 关于强化学习部分，对于source domain里的每个样本，RL会做一个action(选或者不选)，每个batch都有一个immediate reward r。对每个样本，其state由三个
部分组成，TL模型学到的表示h，源模型loss, target模型loss，源模型的prediction，target模型的prediction
5) Ruder and Plank提出了基于贝叶斯方法的样本选择算法，Learning to Select Data for Transfer Learning With Bayesian Optimization
