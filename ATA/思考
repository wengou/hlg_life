1. 125424
1) 风向标：交互式推荐在猜你喜欢的创新尝试 
2) 关于交互式推荐，参考KDD 2018的文章: A Two-Stage Approach toward Interactive Recommendation 
3) 交互式推荐的具体做法是，当用户浏览推荐系统的Item时，系统会生成一个问题来咨询用户的相关信息，
系统可以根据用户的反馈获取到用户的即时兴趣，从而进行item推荐。
4) 交互式推荐分为3个模块：[1]问题生成模块，目前并没有智能到生成问题的地步，而是将其转换成一个关键词推荐问题，关键词候选来自用户搜索日志。
[2]用户反馈，包括用户是否点了某个关键词，以及之前的一些行为；[3]最后就是根据关键词进行搜索。
5) 关于Attention GRU的改进思路可以借鉴：[1] 不同的行为有不同的权重，加购的权重比点击的权重要更大，因此对原lstm的d维的hidden state重新做了一个投影(用一个d*d维的矩阵) 
[2] 引入时间衰减因子，不同时间的行为对当前的影响也不同。[3] 排序的时候要考虑trigger item(触发该query的item)的信息。

2. Pointer Networks简介及其应用
1) https://zhuanlan.zhihu.com/p/48959800
2) seq2seq模型, Attention Mechanism的作用就是将encoder的隐状态按照一定权重加和之后拼接（或者直接加和）到decoder的隐状态上，
   以此作为额外信息，起到所谓“软对齐”的作用;
3) 传统的seq2seq模型是无法解决输出序列的词汇表会随着输入序列长度的改变而改变的问题的，如寻找凸包等. 根据传统的注意力机制，作者想到，
   所谓的正是针对输入序列的权重，完全可以把它拿出来作为指向输入序列的指针，在每次预测一个元素的时候找到输入序列中权重最大的那个元素不就好了嘛！
4) 我们可以发现，因为输出元素来自输入元素的特点，Pointer Networks特别适合用来直接复制输入序列中的某些元素给输出序列

3. 使用Pointer-Generator网络的文本摘要方法:Get To The Point: Summarization with Pointer-Generator Networks
1) 用于文本摘要的seq2seq模型往往存在两大缺陷：1、模型容易不准确地再现事实细节，也就是说模型生成的摘要不准确；2、往往会重复，
   也就是会重复生成一些词或者句子。而针对这两种缺陷，作者分别使用Pointer Networks和Coverage技术来解决。

4. 125196
1) 使用迁移学习，提升搜索多个场景的效果，做法有两种，一种是共享参数，直接迁移模型; 另一种是从数据丰富的场景迁移样本到数据不丰富的样本。
2) 第一种模型迁移的方法：
   [1] ID特征的embedding，分为两个part，一个part是多场景共享的，另一个part是每个domain特定的;
   [2] 猜测是对每个不同的场景分别有一个自己对应的attention层，用于按照本场景的需求计算embedding特征的权重,使用w_i*e_i进行转换;
   [3] 在attention layer后接特征提取的NN网络，多个场景共享一个common特征提取网络，同时各个场景有自己特有的特征提取网络;
   [4] 损失函数是包含src domain和target domain的logloss，同时还会增加Wasserstein distance强迫两个领域的common特征距离小，
       两个领域各自的common特征和domain特征距离大。
3) 第二种迁移样本方法：
   [1] 一共牵涉到3个模块，discriminative model, selection model, TL model;
   [2] discriminative model的目标是，区分选出来的来自于源域的样本与目标域的样本
   [3] selection model的目标包括两个，一个是discriminative model区分不出来的样本(这一部分是一个立即奖励，即为判别模型的对数似然)，
       另一个是要使得TL模型在验证数据集上的loss变小(这是一个延迟奖励),
   [4] TL model就是普通的分类模型;

5. 124362
1）商品特征是多模态的，以前的方法是平等地处理多种模态，然而针对商品给予不同模态不同的重要性（比如对服饰类的商品，图像特征应该具备更大的作用；
   对快消类的商品，统计特征应该具有更大的作用）。本文提出的方法，可以学习不同模态的不同贡献，并同时利用多种模态的互补性和冗余性。
2) 多模态特征可能包含不利于区分不同模态贡献的冗余信息，比如图片和标题里都可能包含'粉色'这个颜色信息，这个信息在学习模态的重要性权重时应该被忽略。
3) 模型的整体结构为，使用MAF网络提取模态特定信息s_m，使用DDMA网络提取模态不变特征c_m，将s_m和c_m做element wise的加法得到item的表示。
4) 得到Item表示后，使用PGRU将用户行为序列串联起来，得到每个item的隐层表示h，然后和候选商品做attention，进而结合attention分数得到user表示。
   将user representation和item repr concat起来输入到后面的ctr预估模型中。
6) MAF网络的结构为，对每个模态，从初始的特征(如图像是vgg 4096维)进行投影得到s_m,然后使用类别的embedding和s_m一起计算element wise
   的attention a_score，然后将a_score乘以s_m
7） DDMA的模型为，双对抗模型，D0使用c_m训练，得到每个c_m属于自身模态的概率d，1-d就是该模态里包含通用特征的degree；另一个判别器
    D2，和通用投影层
I
