1. 125678
[1]多任务学习主要解决单个场景样本不够的问题，即使单个场景样本足够，多任务也会有用。
[2]单任务模型往往难以取得最优解，多任务可以从多个方向逼近最优解，从而提高泛化能力。
[3]思路是 建立CTR任务和CVR任务的多任务学习模型，底层Embedding共享，上层使用CTR的相应层对CVR的相应层进行校正，
   校正的方法是基于Ctr相应层计算一个Sigmoid向量，乘在原来CVR层；
[4]具体做法是Ctr和Cvr交替训练，样本1:1的方式。 所以我们也可以借鉴这个思路，使用首猜数据和洋淘本场景数据一起训练; 该思路可以整入项目中;

2. 152328
[1] 除了考虑用户的点击正反馈外，还要考虑用户的曝光负反馈，因为单纯的点击并不足以表示用户兴趣;
[2] 关于异构行为的建模，这里的异构有两种，一种是用户行为和交互商品的异构，另一种是曝光行为和点击行为的异构；
    对于第一种异构，考虑到只有同构的输入Attention才有意义，因此对于Attention的三元组(Q, K, V), Q是待排序商品的Encoder, 
    K是行为序列中的商品的Encoder, V是商品信息和行为信息fushion的向量； 
    对于第二种，对用户的曝光行为和点击行为分别分开考虑，防止稀疏的点击行为被大量的曝光行为所掩盖;
[3] 在推荐场景里，IPV和PV相比搜索场景的GMV来说Reward信号不会太稀疏;
[4] 跳失点预估，预估用户接下来是否'跳失/满意'的概率，选取用户短期快速离开的Item作为负样本，选取用户浏览较长的列表中，高CTR的作为正样本;
[5] 如果当前训练的模型非常偏重点击行为特征，对于低活用户、新用户本身的点击行为就非常稀疏，模型的推荐结果就会有偏; 文章建议基于meta-learning，
    Few shot learning来解决冷启动问题;
    
3. 101633
[1] 假定广告优化目标是RPM，当前的LogLoss损失以及评价指标AUC均无法反应该优化目标，因此提出了一种新的损失和评价指标;
[2] 评价指标是Real Valued AUC，将广告按照实际RPM从高到低排序，对每个曝光i，遍历其后续的曝光j, sum_i_j(rpm_j - rmp_i)【Z1】得到理想排序时的状况，
    再根据rank score排序，同样计算sum_i_j(rpm_j - rmp_i) 【Z2】, Z1/Z2 就得到[-1, 1]之间的值;
[3] 损失函数受logloss的启发，采用了soft_auc的方式,sum_i_j[sig(Y_i' - Y_j')*(Y_i - Y_j) + sig(Y_j' - Y_i')*(Y_j - Y_i)]
